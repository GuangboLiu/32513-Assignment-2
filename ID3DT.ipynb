{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1JabXpLW9XQ6slmv2UNjexRVJcRs8KADy","authorship_tag":"ABX9TyMXNejLKL/rxE4gPgbrNecJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from math import log\n","\n","def entropy(data_iris):\n","  tmp={'setosa':1e-10,'versicolor':1e-10,'virginica':1e-10}\n","  for j in range(len(data_iris)):\n","    #print(data_iris[j])\n","    if data_iris[j][-1]=='\"setosa\"':\n","      tmp['setosa']+=1\n","    elif data_iris[j][-1]=='\"versicolor\"':\n","      tmp['versicolor']+=1\n","    else:\n","      tmp['virginica']+=1\n","  #print(tmp)\n","  sum=returnSum(tmp)\n","  p1=tmp['setosa']/sum\n","  p2=tmp['versicolor']/sum\n","  p3=tmp['virginica']/sum\n","  return -p1*log(p1)-p2*log(p2)-p3*log(p3)\n","\n","def returnSum(mydict):\n","  sum = 0\n","  for i in mydict:\n","    sum = sum +mydict[i]\n","  return sum\n","\n","def make_dataset():\n","  with open('iris.csv') as f:\n","    data = f.read()\n","    data = data.split()\n","    data_iris=[]\n","  for i in range(len(data)):\n","    data_iris.append(data[i].split(','))\n","    if i!=0:\n","      data_iris[i][1]=float(data_iris[i][1])\n","      data_iris[i][2]=float(data_iris[i][2])\n","      data_iris[i][3]=float(data_iris[i][3])\n","      data_iris[i][4]=float(data_iris[i][4])\n","  return data_iris\n","\n","\n","def informative_attribute(data_iris,ori_entropy,list):\n","  result=[]\n","  best_edge = 0\n","  best_gain = 0\n","  best_class1 = []\n","  best_class2 = []\n","  flag=0\n","  for i in list:\n","    for j in range(len(data_iris)):\n","      if data_iris[j][0] != 'Row':\n","        edge=data_iris[j][i]\n","        class1=[]\n","        class2=[]\n","        for t in range(len(data_iris)):\n","          if data_iris[t][0] != 'Row':\n","            if data_iris[t][i]>=edge:\n","              class1.append(data_iris[t])\n","            else :\n","              class2.append(data_iris[t])\n","        gain= ori_entropy-(len(class1)/len(data_iris))*entropy(class1)-(len(class2)/len(data_iris))*entropy(class2)\n","        if gain>best_gain:\n","            best_gain=gain\n","            best_edge=edge\n","            best_class1=class1\n","            best_class2=class2\n","            flag=i\n","  return [flag,best_edge,best_gain],best_class1,best_class2\n","\n","data_iris=make_dataset()\n","\n","result1,class2_1,class2_2=informative_attribute(data_iris,entropy(data_iris),[1,2,3,4])\n","print(result1)\n","\n","result2_1,class3_1,class3_2=informative_attribute(class2_1,entropy(class2_1),[1,2,4])\n","print(result2_1)\n","\n","result2_2,class3_3,class3_4=informative_attribute(class2_2,entropy(class2_2),[1,2,4])\n","print(result2_2)\n","\n","result3_1,class4_1,class4_2=informative_attribute(class3_1,entropy(class3_1),[1,2])\n","print(result3_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpufszB7A8Ju","executionInfo":{"status":"ok","timestamp":1665966386623,"user_tz":-660,"elapsed":270,"user":{"displayName":"刘光博","userId":"07277295616820519425"}},"outputId":"1526a3b9-1a82-4381-c4e0-1268cb4d5f2d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 3.0, 0.6395306588273012]\n","[4, 1.8, 0.47838271508979024]\n","[0, 0, 0]\n","[1, 6.0, 0.04232343403765624]\n"]}]}]}